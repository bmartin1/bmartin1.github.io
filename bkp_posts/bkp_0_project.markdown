---
layout: page
title: 0
description: Everyday, sounds occur around us.
img: /assets/img/applications.png
importance: 0
---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ '/assets/img/kitchen.jpg' | relative_url }}" alt="" title="example image"/>
    </div>
</div>
<div class="caption">
    The acoustic scene of a kitchen is composed by sounds that carry a meaning and allow inhabitants to react accordingly. For example, the sound of the espresso pot whistling indicates that the water is hot.
</div>

Everyday situations are rarely silent, and in most cases, sounds occur around us, many of which can be interpreted to make us react accordingly.
<br><br>

Think about how much information can be inferred by the acoustics in the kitchen depicted in the figure. Some sound events are produced in order to convey specific messages, such as a espresso pot whistling indicates that the water is hot, or the microwave's bell alerts that the food is ready. Other sounds occur without the intention of conveying a message, but based on the context, these sounds can be meaningful, such as the refrigerator's steady buzzing indicates that it's on and working normally, a toaster ejecting bread indicates it's toasted, and the scrubbing of ceramic plates with water flowing on and off indicates that someone is washing the dishes. This complex array of sound events represent an acoustic scene, which convey essential information in people's lives.
<br><br>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ '/assets/img/applications.png' | relative_url }}" alt="" title="example image"/>
    </div>
</div>
<div class="caption">
  Examples of applications that employ systems capable of Acoustic Intelligence.
</div>

 Acoustic Intelligence (also known as Sound Understanding or Audio Analytics) is an emerging field of Machine Hearing [1], which aims to build systems that can automatically recognize sounds in order to extract meaning that helps us react accordingly. Such artificial intelligence-based systems rely on Machine Learning and Audio Signal Processing, and are being used in multiple applications.

•	In Healthcare, [Sound Intelligence](https://www.soundintel.com/) have developed acoustic monitoring systems for hospital rooms to identify sounds that imply emergencies for patients in order to alert the caregiver, such as the sound of a person moaning.

•	In 2020, the Apple Watch uses its motion sensors and microphones to detect hand-washing movements and water-flowing sounds. If the user finishes washing their hands too early, the watch will prompt a message to keep washing.

•	For Smart Homes, [Audio Analytics](https://www.audioanalytic.com/) employ acoustic sensors to detect domestic and safety related sounds, such as dog barking, glass breaking and baby crying.

•	Digital assistants identify human-produced sounds to enhance our interaction with them. For example, Amazon Alexa recognizes spoken language and  will soon recognize laughter too. We could take laughter recognition one step further, if Alexa tells us a joke and recognizes our different types of laughter, it could adapt the jokes to our humor.

•	In Automotive, Waymo's self-driving cars identify sounds to respond safely to emergency vehicles and traffic warnings [2]. For example, the sound of a wailing siren from an emergency vehicle can be heard miles away. Depending on where the sound is coming from, the car will react accordingly, if it's coming from behind, the car has to pull over, but if it's coming ahead the car has to stop.

•	For Security and Surveillance in the urban context, sounds are identified to detect safety-related events, like glass breaking or gun shots. New York University and local authorities are doing this as part of the [SONYC](https://wp.nyu.edu/sonyc/) project, which uses acoustic sensors located across New York City's downtown.

•	Acoustic monitoring of machinery identify sounds to determine whether machines need to be repaired or replaced. For example, in 2020 Bosch Research presented a device called [SoundSee](https://www.bosch.com/stories/acoustic-sensors/) which monitors machines in the International Space Station.

•	Everyday people record their lives and shared them in social media. In fact, over 82% of the consumer traffic on the Internet are videos according to CISCO [3]. The soundtrack contains all kinds of sounds that can be used to index and organize content. Microsoft began offering recognition of audience reaction sounds (e.g. laughing, clapping, booing) in the [Azure's Video Indexer](https://azure.microsoft.com/en-us/services/media-services/video-indexer/) tool in 2020. YouTube started in 2017 by adding captioning of three sounds to their videos -- applause, music, laughter [4].

Consumer products capable of Acoustic Intelligence have emerged in recent years and their
market size is expected to grow exponentially and reach USD 4.42 billion by 2025 [5]. Current products consist of recognition of a few sounds, but we should look into the next frontiers of the technology. The next generation of products will aim to understand the meaning of sounds in a given context and perform more abstract tasks in isolation and in multimodal setups. We will see more examples like the Waymo application were a sound is recognized and its meaning is interpreted. Sound recognition will be available in hearables and smart speakers. Acoustic monitoring of homes will be essential for Assisted Living. Acoustic Intelligence will enhance how computers hear beyond speech.

<h3>References</h3>
1. Lyon, Richard F. "Machine hearing: An emerging field [exploratory dsp]." IEEE signal processing magazine 27.5 (2010): 131-139.
2. Waymo. (2017, July 10). ["Recognizing the sights and sounds of emergency vehicles"](https://blog.waymo.com/2019/08/recognizing-sights-and-sounds-of.html)
3. CISCO. (2020, March 9). ["Cisco Annual Internet Report (2018–2023)"](https://www.cisco.com/c/en/us/solutions/collateral/executive-perspectives/annual-internet-report/white-paper-c11-741490.html#_Toc484813971)
4. Chaudhuri Sourish.(2017, March 23).  ["Adding Sound Effect Information to YouTube Captions"](https://ai.googleblog.com/2017/03/adding-sound-effect-information-to.html)
5. Grand View Research. (2019, December). [“Sound recognition market worth 4.42 billion by 2025”](https://www.grandviewresearch.com/press-release/global-sound-recognition-market)
